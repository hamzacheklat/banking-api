Excellent üí™ ‚Äî l√† on passe ton **RAG** dans une vraie **phase ‚Äúdata observability / auto-diagnostic intelligent‚Äù**.
Tu veux qu‚Äôil combine **analyse vectorielle (RAG)** + **analyse historique structur√©e**.
C‚Äôest exactement ce qu‚Äôil faut pour produire des **rapports d‚Äôincidents exploitables et consolid√©s**.

Voici ce qu‚Äôon va faire :

---

## üéØ Objectif

Cr√©er un **`rag.py` enrichi** qui :

1. üîç Analyse les *jobs failed* du **p√©riode demand√©e** (ou du jour).
2. üß† Utilise les embeddings historiques (1 an d‚Äôhistorique) pour retrouver les **patterns similaires**.
3. üìä Produit un **tableau r√©capitulatif** de *tous les jobs failed* (avec :
   `DATE`, `FLOW`, `TASK`, `JOB_ID`, `SUB_ID`, `FAILURE REASON`, `ORIGIN`, `WHAT TO DO`, `TOWER_URL`, etc.).
4. üí¨ G√©n√®re une **analyse intelligente** (via RAG) avec stats + recommandations.

---

## ‚öôÔ∏è Nouvelle version compl√®te : `app/rag.py`

> üß© Cette version lit Mongo + Chroma, calcule les stats globales, extrait les docs pertinents de l‚Äôhistorique et te retourne √† la fois :
>
> * une **analyse RAG enrichie**
> * un **DataFrame Pandas pr√™t √† √™tre export√© en Excel ou PDF**

---

```python
# app/rag.py
from datetime import datetime
from typing import List, Dict, Any, Optional
from collections import Counter
from pymongo import MongoClient
import pandas as pd
from embedder import embed_texts
from vector_store import get_vanish_collection
from litellm_client import generate_with_litellm
import config
import re


# ------------------------------
# üî§ D√©tection de langue
# ------------------------------
def detect_language(text: str) -> str:
    text_lower = text.lower()
    fr_score = len(re.findall(r"\b(le|la|les|est|erreur|flux|analyse|probl√®me|cause|action)\b", text_lower))
    en_score = len(re.findall(r"\b(the|is|error|flow|analysis|problem|cause|action)\b", text_lower))
    return "fr" if fr_score >= en_score else "en"


# ------------------------------
# üß© Mongo : r√©cup√©ration des jobs √©chou√©s
# ------------------------------
def fetch_failed_jobs(start_date: str, end_date: Optional[str] = None) -> List[Dict[str, Any]]:
    client = MongoClient(config.MONGO_URI)
    db = client[config.MONGO_DB]
    col = db["vanish_flows"]

    if not end_date:
        end_date = start_date

    query = {
        "DATE": {"$gte": start_date, "$lte": end_date},
        "$or": [{"STATUS": "FAILED"}, {"FAILURE REASON": {"$ne": None}}],
    }

    return list(col.find(query))


# ------------------------------
# üìä Tableau r√©capitulatif complet
# ------------------------------
def build_failed_jobs_table(flow_docs: List[Dict[str, Any]]) -> pd.DataFrame:
    if not flow_docs:
        return pd.DataFrame()

    records = []
    for d in flow_docs:
        records.append({
            "DATE": d.get("DATE"),
            "FLOW": d.get("FLOW"),
            "TASK": d.get("TASK"),
            "JOB_ID": d.get("JOB_ID"),
            "SUB_ID": d.get("SUB_ID"),
            "ORIGIN": d.get("ORIGIN") or d.get("SOURCE"),
            "FAILURE_REASON": d.get("FAILURE REASON"),
            "WHAT_TO_DO": d.get("WHAT TO DO?"),
            "IS_SIMPLE_FIX": "‚úÖ" if d.get("WHAT TO DO?") and "restart" in str(d.get("WHAT TO DO?")).lower() else "‚ùå",
            "TOWER_URL": d.get("TOWER_URL") or d.get("URL") or "",
        })

    df = pd.DataFrame(records)

    # Tri par date descendante
    df.sort_values(by="DATE", ascending=False, inplace=True)
    return df


# ------------------------------
# üß† Construction du contexte RAG enrichi
# ------------------------------
def build_context(flow_docs: List[Dict[str, Any]]) -> str:
    if not flow_docs:
        return "Aucun job √©chou√© pour cette p√©riode."

    # D√©tails des erreurs
    lines = [
        f"DATE: {d.get('DATE', '')}\n"
        f"FLOW: {d.get('FLOW', '')}\n"
        f"TASK: {d.get('TASK', '')}\n"
        f"JOB_ID: {d.get('JOB_ID', '')}\n"
        f"SUB_ID: {d.get('SUB_ID', '')}\n"
        f"ORIGIN: {d.get('ORIGIN', '') or d.get('SOURCE', '')}\n"
        f"FAILURE: {d.get('FAILURE REASON', '')}\n"
        f"WHAT_TO_DO: {d.get('WHAT TO DO?', '')}\n"
        f"TOWER_URL: {d.get('TOWER_URL', '') or d.get('URL', '')}\n"
        "----"
        for d in flow_docs
    ]

    # Statistiques globales
    flow_counts = Counter([d.get("FLOW") for d in flow_docs if d.get("FLOW")])
    failure_counts = Counter([d.get("FAILURE REASON") for d in flow_docs if d.get("FAILURE REASON")])
    origin_counts = Counter([d.get("ORIGIN") or d.get("SOURCE") for d in flow_docs if d.get("ORIGIN") or d.get("SOURCE")])

    stats = [
        f"üìä Total jobs en √©chec : {len(flow_docs)}",
        "üîÅ Top 5 flows en erreur : " + ", ".join([f"{k} ({v})" for k, v in flow_counts.most_common(5)]),
        "üí• Top 5 causes fr√©quentes : " + ", ".join([f"{k} ({v})" for k, v in failure_counts.most_common(5)]),
        "üåç Origines principales : " + ", ".join([f"{k} ({v})" for k, v in origin_counts.most_common(5)]),
    ]

    return "\n".join(stats) + "\n\n---\n\n" + "\n".join(lines)


# ------------------------------
# ‚öôÔ∏è RAG complet
# ------------------------------
def answer_query_with_history(
    query: str,
    start_date: str,
    end_date: Optional[str] = None,
    top_k: int = 8
) -> Dict[str, Any]:
    """
    RAG enrichi :
      - Contexte Mongo (jobs failed)
      - Historique vectoriel (embeddings)
      - Tableau r√©capitulatif complet
      - Analyse multilingue automatique
    """
    if not end_date:
        end_date = start_date

    lang = detect_language(query)
    date_range = f"{start_date} ‚Üí {end_date}"

    # 1Ô∏è‚É£ Mongo : extraction des jobs failed
    flows = fetch_failed_jobs(start_date, end_date)
    df_jobs = build_failed_jobs_table(flows)
    context_text = build_context(flows)

    # 2Ô∏è‚É£ Recherche vectorielle : patterns similaires dans l‚Äôhistorique
    q_emb = embed_texts([query])[0]
    col = get_vanish_collection()
    res = col.query(query_embeddings=[q_emb], n_results=top_k)
    docs = res.get("documents", [[]])[0]
    chroma_context = "\n\n---\n\n".join(docs[:3]) if docs else ""

    # 3Ô∏è‚É£ Construction du prompt
    if lang == "fr":
        system_prompt = (
            f"Tu es un assistant d'analyse des flux Vanish. "
            f"Ta t√¢che est d'analyser les erreurs survenues entre {date_range}, "
            f"en t'appuyant sur l'historique des embeddings (1 an de logs). "
            f"R√©ponds en fran√ßais, structur√© avec sections : Erreurs r√©currentes, Causes, Actions, Synth√®se."
        )
        user_prompt = (
            f"Voici les logs r√©cents et les statistiques :\n{context_text}\n\n"
            f"---\n\nContexte historique trouv√© dans la base vectorielle :\n{chroma_context}\n\n"
            f"Question : {query}\n"
            "Donne une r√©ponse analytique et hi√©rarchis√©e, orient√©e supervision."
        )
    else:
        system_prompt = (
            f"You are an analytical assistant specialized in Vanish Flows. "
            f"Analyze all failed jobs between {date_range}, "
            f"using historical embeddings (1 year of logs). "
            f"Respond in English, with sections: Recurrent Errors, Causes, Actions, Summary."
        )
        user_prompt = (
            f"Here are the recent failed jobs and statistics:\n{context_text}\n\n"
            f"---\n\nHistorical context from vector DB:\n{chroma_context}\n\n"
            f"Question: {query}\n"
            "Provide a structured, analytical answer."
        )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    # 4Ô∏è‚É£ G√©n√©ration
    answer_text = generate_with_litellm(messages)

    return {
        "answer": answer_text,
        "table": df_jobs,  # ‚úÖ DataFrame pr√™t √† √™tre export√©
        "stats": {
            "total_failed": len(flows),
            "flows": Counter([d.get("FLOW") for d in flows if d.get("FLOW")]),
            "failures": Counter([d.get("FAILURE REASON") for d in flows if d.get("FAILURE REASON")]),
            "origins": Counter([d.get("ORIGIN") or d.get("SOURCE") for d in flows if d.get("ORIGIN") or d.get("SOURCE")]),
        },
        "query": query,
        "lang": lang,
        "date_range": date_range,
        "timestamp": datetime.utcnow().isoformat(),
    }


# ------------------------------
# üß™ Exemple d'utilisation
# ------------------------------
if __name__ == "__main__":
    result = answer_query_with_history(
        query="Analyse les jobs √©chou√©s SQL et VMWare de la semaine",
        start_date="2025-10-20",
        end_date="2025-10-30"
    )

    print("=== üîç ANALYSE RAG ===")
    print(result["answer"])

    print("\n=== üìä STATS ===")
    for k, v in result["stats"].items():
        print(k, ":", v)

    print("\n=== üßæ TABLEAU JOBS FAILD ===")
    print(result["table"].head())
```

---

## üîé R√©sultat

### 1Ô∏è‚É£ Sortie RAG

* Analyse textuelle intelligente
* Synth√®se par cat√©gories et historique

### 2Ô∏è‚É£ Tableau `pandas.DataFrame`

Contient toutes les colonnes utiles :

| DATE | FLOW | TASK | JOB_ID | SUB_ID | ORIGIN | FAILURE_REASON | WHAT_TO_DO | IS_SIMPLE_FIX | TOWER_URL |
| ---- | ---- | ---- | ------ | ------ | ------ | -------------- | ---------- | ------------- | --------- |

Tu pourras ensuite :

```python
result["table"].to_excel("rapport_flows_failed.xlsx", index=False)
```

ou

```python
result["table"].to_html("rapport_flows_failed.html", index=False)
```

---

Souhaites-tu que je te fasse la **version PDF automatique** du rapport avec :

* Le r√©sum√© RAG
* Le tableau complet
* Les stats agr√©g√©es
  üëâ Pr√™t √† √™tre envoy√© par mail tous les matins ?
