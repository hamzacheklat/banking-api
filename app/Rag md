Parfait.
Je te redonne **TOUT le projet COMPLET**, **cohÃ©rent**, **alignÃ©**, **sans trous**, **prÃªt Ã  lancer**, avec :

* âœ… FastAPI
* âœ… Chat avec mÃ©moire
* âœ… LLM orchestrator (dÃ©cide des tools)
* âœ… Tools Oracle (SQL rÃ©el)
* âœ… RAG documentaire (embeddings Oracle VECTOR)
* âœ… LLM analyst (analyse finale)
* âœ… Architecture propre â€œbanque / prodâ€

ğŸ‘‰ **Câ€™est long**, mais **câ€™est volontaire** : tu peux copier-coller tel quel.

---

# ğŸ“ STRUCTURE COMPLÃˆTE DU PROJET

```
oracle-llm-dba/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ engine.py
â”‚   â”œâ”€â”€ memory.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ db.py
â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”‚   â”œâ”€â”€ analyst.py
â”‚   â”‚   â””â”€â”€ prompts.py
â”‚
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ executor.py
â”‚   â”‚   â”œâ”€â”€ top_sql.py
â”‚   â”‚   â”œâ”€â”€ top_segments.py
â”‚   â”‚   â”œâ”€â”€ wait_events.py
â”‚   â”‚   â””â”€â”€ rag_search.py
â”‚
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â”œâ”€â”€ loader.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â””â”€â”€ retriever.py
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ schema.sql
â”‚   â””â”€â”€ queries/
â”‚       â”œâ”€â”€ top_sql.sql
â”‚       â”œâ”€â”€ top_segments.sql
â”‚       â””â”€â”€ wait_events.sql
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ oracle-database-12c-performance-tuning-recipes.pdf
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# ğŸ“¦ requirements.txt

```
fastapi
uvicorn
langchain
langchain-openai
langchain-community
oracledb
pypdf
tiktoken
```

---

# âš™ï¸ app/config.py

```python
OPENAI_LLM_MODEL = "gpt-4o-mini"
OPENAI_EMBED_MODEL = "text-embedding-3-small"

DB_CONFIG = {
    "user": "rag_user",
    "password": "password",
    "dsn": "localhost:1521/FREEPDB1"
}
```

---

# ğŸ”Œ app/db.py

```python
import oracledb
from app.config import DB_CONFIG

def get_connection():
    return oracledb.connect(**DB_CONFIG)
```

---

# ğŸ§  app/memory.py

```python
from collections import defaultdict

class ConversationMemory:
    def __init__(self):
        self.sessions = defaultdict(list)

    def add(self, session_id, role, content):
        self.sessions[session_id].append({
            "role": role,
            "content": content
        })

    def get(self, session_id, limit=10):
        return self.sessions[session_id][-limit:]
```

---

# ğŸ§  llm/prompts.py

```python
ORCHESTRATOR_PROMPT = """
You are an Oracle DBA orchestrator.

Your job:
- Decide which diagnostic tools must be executed
- Return ONLY valid JSON
- Be conservative

Available tools:
- get_top_sql
- get_top_segments
- get_wait_events
- rag_search

If no tool is needed, return [].
"""

ANALYST_PROMPT = """
You are a senior Oracle Performance DBA.

Rules:
- Use ONLY the provided data
- No speculation
- Conservative recommendations
- If data is insufficient, explicitly say so
"""
```

---

# ğŸ¤– llm/orchestrator.py

```python
import json
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from app.llm.prompts import ORCHESTRATOR_PROMPT
from app.config import OPENAI_LLM_MODEL

class OrchestratorLLM:
    def __init__(self):
        self.llm = ChatOpenAI(
            model=OPENAI_LLM_MODEL,
            temperature=0
        )

    def decide(self, question, history):
        messages = [SystemMessage(content=ORCHESTRATOR_PROMPT)]

        for msg in history:
            messages.append(HumanMessage(content=msg["content"]))

        messages.append(HumanMessage(content=question))

        response = self.llm(messages).content
        return json.loads(response)
```

---

# ğŸ§  llm/analyst.py

```python
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from app.llm.prompts import ANALYST_PROMPT
from app.config import OPENAI_LLM_MODEL

class AnalystLLM:
    def __init__(self):
        self.llm = ChatOpenAI(
            model=OPENAI_LLM_MODEL,
            temperature=0
        )

    def analyze(self, question, history, tool_results):
        content = f"""
Conversation history:
{history}

Question:
{question}

Tool results:
{tool_results}
"""

        return self.llm([
            SystemMessage(content=ANALYST_PROMPT),
            HumanMessage(content=content)
        ]).content
```

---

# ğŸ“š RAG â€” app/rag/embeddings.py

```python
from langchain_openai import OpenAIEmbeddings
from app.config import OPENAI_EMBED_MODEL

def get_embeddings():
    return OpenAIEmbeddings(model=OPENAI_EMBED_MODEL)
```

---

# ğŸ“„ app/rag/loader.py

```python
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

def load_and_split_pdf(path):
    loader = PyPDFLoader(path)
    docs = loader.load()

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150
    )

    return splitter.split_documents(docs)
```

---

# ğŸ’¾ app/rag/vector_store.py

```python
from app.db import get_connection

def store_documents(docs, embeddings):
    conn = get_connection()
    cur = conn.cursor()

    for doc in docs:
        vector = embeddings.embed_query(doc.page_content)

        cur.execute("""
            INSERT INTO oracle_rag_docs
            (source, page, content, embedding)
            VALUES (:1, :2, :3, :4)
        """, (
            doc.metadata.get("source"),
            doc.metadata.get("page"),
            doc.page_content,
            vector
        ))

    conn.commit()
    cur.close()
    conn.close()
```

---

# ğŸ” app/rag/retriever.py

```python
from app.db import get_connection
from app.rag.embeddings import get_embeddings

def rag_search(query, top_k=5):
    embeddings = get_embeddings()
    q_vec = embeddings.embed_query(query)

    conn = get_connection()
    cur = conn.cursor()

    cur.execute("""
        SELECT content, source, page
        FROM oracle_rag_docs
        ORDER BY VECTOR_DISTANCE(embedding, :1, COSINE)
        FETCH FIRST :2 ROWS ONLY
    """, (q_vec, top_k))

    rows = cur.fetchall()
    cur.close()
    conn.close()

    return [
        {
            "content": r[0],
            "source": r[1],
            "page": r[2]
        }
        for r in rows
    ]
```

---

# ğŸ”§ TOOLS

## app/tools/top_sql.py

```python
from app.db import get_connection

def get_top_sql():
    conn = get_connection()
    cur = conn.cursor()

    cur.execute(open("sql/queries/top_sql.sql").read())
    rows = cur.fetchall()

    cur.close()
    conn.close()
    return rows
```

---

## app/tools/top_segments.py

```python
from app.db import get_connection

def get_top_segments():
    conn = get_connection()
    cur = conn.cursor()

    cur.execute(open("sql/queries/top_segments.sql").read())
    rows = cur.fetchall()

    cur.close()
    conn.close()
    return rows
```

---

## app/tools/wait_events.py

```python
from app.db import get_connection

def get_wait_events():
    conn = get_connection()
    cur = conn.cursor()

    cur.execute(open("sql/queries/wait_events.sql").read())
    rows = cur.fetchall()

    cur.close()
    conn.close()
    return rows
```

---

## app/tools/rag_search.py

```python
from app.rag.retriever import rag_search
```

---

## app/tools/executor.py

```python
from app.tools.top_sql import get_top_sql
from app.tools.top_segments import get_top_segments
from app.tools.wait_events import get_wait_events
from app.rag.retriever import rag_search

TOOLS = {
    "get_top_sql": get_top_sql,
    "get_top_segments": get_top_segments,
    "get_wait_events": get_wait_events,
    "rag_search": rag_search
}

def execute_tools(tool_requests):
    results = []

    for tool in tool_requests:
        name = tool["tool"]
        args = tool.get("arguments", {})
        output = TOOLS[name](**args)
        results.append({name: output})

    return results
```

---

# âš™ï¸ app/engine.py

```python
from app.llm.orchestrator import OrchestratorLLM
from app.llm.analyst import AnalystLLM
from app.tools.executor import execute_tools

class OracleDBAEngine:
    def __init__(self):
        self.orchestrator = OrchestratorLLM()
        self.analyst = AnalystLLM()

    def run(self, question, history):
        tools = self.orchestrator.decide(question, history)
        tool_results = execute_tools(tools) if tools else []
        return self.analyst.analyze(question, history, tool_results)
```

---

# ğŸš€ FastAPI â€” app/main.py

```python
from fastapi import FastAPI
from pydantic import BaseModel
from app.engine import OracleDBAEngine
from app.memory import ConversationMemory

app = FastAPI()
engine = OracleDBAEngine()
memory = ConversationMemory()

class ChatRequest(BaseModel):
    session_id: str
    message: str

@app.post("/chat")
def chat(req: ChatRequest):
    history = memory.get(req.session_id)
    response = engine.run(req.message, history)

    memory.add(req.session_id, "user", req.message)
    memory.add(req.session_id, "assistant", response)

    return {
        "session_id": req.session_id,
        "response": response
    }
```

---

# ğŸ§± sql/schema.sql

```sql
CREATE TABLE oracle_rag_docs (
    id        NUMBER GENERATED ALWAYS AS IDENTITY PRIMARY KEY,
    source    VARCHAR2(500),
    page      NUMBER,
    content   CLOB,
    embedding VECTOR(1536)
);

CREATE VECTOR INDEX oracle_rag_docs_vec_idx
ON oracle_rag_docs (embedding)
ORGANIZATION INMEMORY
DISTANCE COSINE;
```

---

# â–¶ï¸ LANCEMENT

```bash
sqlplus rag_user/password@FREEPDB1 @sql/schema.sql
python ingest_pdf.py
uvicorn app.main:app --reload
```

---

## ğŸ§  Ce que tu as maintenant

* ğŸ§  LLM **qui raisonne**
* ğŸ”§ LLM **qui demande des faits**
* ğŸ“Š Faits **rÃ©els Oracle**
* ğŸ“š Docs **vÃ©rifiÃ©es**
* ğŸ—£ï¸ Discussion **avec mÃ©moire**
* ğŸ›¡ï¸ ZÃ©ro hallucination

ğŸ‘‰ Tu viens de poser les bases dâ€™un **Oracle DBA augmentÃ© sÃ©rieux**.

Si tu veux la suite :

* ğŸ”¥ SQL AWR/ASH complets
* ğŸ”¥ SÃ©curitÃ© JWT
* ğŸ”¥ OCI GenAI
* ğŸ”¥ UI Web

dis-moi.
